"""
This script implements evaluation metrics for different tasks.
"""

import time
from collections import Counter
from typing import List, Union

import numpy as np
from tqdm.auto import tqdm

from evaluate import load


def compute_rouge2_score(
    generations: List[str], references: Union[List[List[str]], List[str]]
) -> List[float]:
    """
    Computes ROUGE-2 score over a list of generations and references.

    Args:
        generations (List[str]): List of generated texts
        references (Union[List[List[str]], List[str]]): List of reference texts

    Returns:
        List[float]: List of ROUGE-2 scores
    """
    rouge = load("rouge")
    results = rouge.compute(
        predictions=generations, references=references, use_aggregator=False
    )
    return results["rouge2"]


def squad_acc(generations, references):
    correct = []
    for gen, ref in zip(generations, references):
        if ref.lower() in gen.lower():
            correct.append(1)
        else:
            correct.append(0)
    return correct


def trivia_qa_acc(generations, references):
    correct = []
    for gen, refs in zip(generations, references):
        gen_lower = gen.lower()
        if any(ref.lower() in gen_lower for ref in refs):
            correct.append(1)
        else:
            correct.append(0)
    return correct


# TODO: UPDATE THIS TO INCORPORATE LIST OF REFERENCES
def definition_extraction_acc(generations, references):
    correct = []
    for gen, ref in zip(generations, references):
        gen_lower = gen.lower()
        if ref.lower() in gen_lower:
            correct.append(1)
        else:
            correct.append(0)
    return correct

def gsm8k_acc(generations, references):
    correct = []
    for gen, ref in zip(generations, references):
        gen_sentences = gen.split(".")
        for sentence in gen_sentences:
            if "the answer is" in sentence:
                gen_lower = sentence.lower().replace(",", "")
                ref_lower = ref.lower().replace(",", "")
                if ref_lower in gen_lower:
                    correct.append(1)
                else:
                    correct.append(0)
                break
        else:
            correct.append(0)
    return correct


METRIC_FUNCS = {
    "rouge2": compute_rouge2_score,
    "squad_acc": squad_acc,
    "trivia_qa_acc": trivia_qa_acc,
    "definition_extraction_acc": definition_extraction_acc,
    "gsm8k_acc": gsm8k_acc,
}

MULTI_MODEL_TASK2METRIC = {
    "cnn_dailymail": "rouge2",
    "definition_extraction": "definition_extraction_acc",
    "e2e_nlg": "rouge2",
    "squad": "squad_acc",
    "trivia_qa": "trivia_qa_acc",
    "web_nlg": "rouge2",
    "xsum": "rouge2",
}
